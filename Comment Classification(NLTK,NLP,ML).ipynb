{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лемматизация-и-предобработка-текста\" data-toc-modified-id=\"Лемматизация-и-предобработка-текста-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Лемматизация и предобработка текста</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#DesicionTreeClassifier\" data-toc-modified-id=\"DesicionTreeClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>DesicionTreeClassifier</a></span></li><li><span><a href=\"#LinearSVC\" data-toc-modified-id=\"LinearSVC-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LinearSVC</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Тестовая-выборка\" data-toc-modified-id=\"Тестовая-выборка-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Тестовая выборка</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import catboost as cb\n",
    "\n",
    "# Лемматизация и предобработка\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#Модели\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the tools well.  · talk \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contrary to those of DuLithgow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \"\\n\\nCongratulations from me as well, use the tools well.  · talk \"   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.   \n",
       "8                                                                                                                                                            Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              alignment on this subject and which are contrary to those of DuLithgow   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется лемматизация и очистка текста от лишних символов для перевода их к векторному виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы несбалансированы соотношение 1 к 10,поэтому при обучении моделей надо обязательно использовать сбалансированное взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация и предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):    \n",
    "    text = text.lower()\n",
    "    lemm_text = \"\".join(m.lemmatize(text))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь лемматизируем наш текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 s, sys: 7.57 s, total: 43.5 s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                                                                                                                                                                                                                    explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    d aww he matches this background colour i m seemingly stuck with thanks talk january utc\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                       hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info\n",
       "3    more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it s listed in the relevant form eg wikipedia good article nominationstransport\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             you sir are my hero any chance you remember what page that s on\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку нельзя переводить в векторы всю выборку(из-за утечки данных),сделаем это до векторизации признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['toxic']\n",
    "features = df.drop(['toxic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=.3, \n",
    "                                                                              random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим корректность разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Признаки\n",
      "Обучающая: (111699, 1) Тестовая: (47872, 1)\n",
      "Таргет\n",
      "Обучающая: (47872,)  Тестовая: (47872,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Признаки\")\n",
    "print(f'Обучающая: {features_train.shape} Тестовая: {features_test.shape}')\n",
    "print('Таргет')\n",
    "print(f'Обучающая: {target_test.shape}  Тестовая: {target_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборки разделены нормально, можно приступать к векторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим английский корпус со стоп-словами из библиотеки nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем признаки для обучающей выборки,обучая векторизатор только на тренировачной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = count_tf_idf.fit_transform(features_train['text'])\n",
    "features_test = count_tf_idf.transform(features_test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки подготовлены, можно приступать к обучению моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 5.0, 'intercept_scaling': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Лучший результат:0.7694298872716896\n",
      "CPU times: user 45min 35s, sys: 25min 15s, total: 1h 10min 51s\n",
      "Wall time: 1h 10min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lr = LogisticRegression(random_state = 1234, class_weight='balanced')\n",
    "grid_params= {'penalty': ['l1','l2'], \n",
    "              'C' : [0.5, 1.0, 5.0, 15.0],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "              'intercept_scaling' : range(5, 100, 40)}\n",
    "lr_gs = GridSearchCV(model_lr,cv=3,param_grid = grid_params,n_jobs=-1,scoring='f1')\n",
    "lr_gs.fit(features_train,target_train)\n",
    "print(f'Лучшие параметры: {lr_gs.best_params_}')\n",
    "print(f'Лучший результат:{lr_gs.best_score_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: {'C': 5.0, 'intercept_scaling': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "Лучший результат:0.7694298872716896\n",
    "CPU times: user 45min 35s, sys: 25min 15s, total: 1h 10min 51s\n",
    "Wall time: 1h 10min 58s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DesicionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 30, 'max_leaf_nodes': 50}\n",
      "Лучший результат:0.6294799682091264\n",
      "CPU times: user 1h 8min 35s, sys: 3.32 s, total: 1h 8min 38s\n",
      "Wall time: 1h 8min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtc = DecisionTreeClassifier(random_state=1234,class_weight = 'balanced')\n",
    "grid_params ={'max_depth': range(10, 131, 20),\n",
    "              'max_leaf_nodes': range(10, 61, 20)}\n",
    "dtc_gs = GridSearchCV(dtc,cv=3,param_grid = grid_params,n_jobs=-1,scoring='f1')\n",
    "dtc_gs.fit(features_train,target_train)\n",
    "print(f'Лучшие параметры: {dtc_gs.best_params_}')\n",
    "print(f'Лучший результат:{dtc_gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: {'max_depth': 30, 'max_leaf_nodes': 50}\n",
    "Лучший результат:0.6294799682091264\n",
    "CPU times: user 1h 8min 35s, sys: 3.32 s, total: 1h 8min 38s\n",
    "Wall time: 1h 8min 41s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 1.0, 'max_iter': 300, 'penalty': 'l2'}\n",
      "Лучший результат:0.7633296827075225\n",
      "CPU times: user 1min 35s, sys: 1.21 s, total: 1min 37s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc = LinearSVC(random_state = 1234,class_weight ='balanced')\n",
    "grid_params={'penalty': ['l1','l2'],\n",
    "             'C': np.logspace(-5,5,7),\n",
    "             'max_iter': [100,300,500]}\n",
    "svc_gs = GridSearchCV(svc,cv=3,param_grid = grid_params,n_jobs=-1,scoring='f1')\n",
    "svc_gs.fit(features_train,target_train)\n",
    "print(f'Лучшие параметры: {svc_gs.best_params_}')\n",
    "print(f'Лучший результат:{svc_gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: {'C': 1.0, 'max_iter': 300, 'penalty': 'l2'}\n",
    "Лучший результат:0.7633296827075225\n",
    "CPU times: user 1min 35s, sys: 1.21 s, total: 1min 37s\n",
    "Wall time: 1min 37s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'criterion': 'entropy', 'max_depth': 130, 'n_estimators': 110}\n",
      "Лучший результат:0.5672398003364928\n",
      "CPU times: user 4h 11min 31s, sys: 18 s, total: 4h 11min 49s\n",
      "Wall time: 4h 11min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(random_state = 1234,class_weight ='balanced')\n",
    "grid_params ={  'n_estimators': range(10, 121, 20),\n",
    "                'max_depth': range(10, 131, 20),\n",
    "                'criterion' : ['gini', 'entropy', 'log_loss']}\n",
    "rfc_gs = GridSearchCV(rfc,cv=3,param_grid = grid_params,n_jobs=-1,scoring='f1')\n",
    "rfc_gs.fit(features_train,target_train)\n",
    "print(f'Лучшие параметры: {rfc_gs.best_params_}')\n",
    "print(f'Лучший результат:{rfc_gs.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры: {'criterion': 'entropy', 'max_depth': 130, 'n_estimators': 110}\n",
    "Лучший результат:0.5672398003364928\n",
    "CPU times: user 4h 11min 31s, sys: 18 s, total: 4h 11min 49s\n",
    "Wall time: 4h 11min 51s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**\n",
    "\n",
    "- Лучшие параметры: {'C': 5.0, 'intercept_scaling': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "- Лучший результат F1:**0.769**\n",
    "- CPU times: user 45min 35s, sys: 25min 15s, total: 1h 10min 51s\n",
    "- Wall time: 1h 10min 58s\n",
    "\n",
    "**Desicion Tree Classifier**\n",
    "\n",
    "- Лучшие параметры: {'max_depth': 30, 'max_leaf_nodes': 50}\n",
    "- Лучший результат:**0.629**\n",
    "- CPU times: user 1h 8min 35s, sys: 3.32 s, total: 1h 8min 38s\n",
    "- Wall time: 1h 8min 41s\n",
    "\n",
    "*Данную модель мы не будем использовать для проверки на тестовой выборке ,т.к. она не проходит по минимальным требованиям метрики*\n",
    "\n",
    "**LinearSVC**\n",
    "\n",
    "- Лучшие параметры: {'C': 1.0, 'max_iter': 300, 'penalty': 'l2'}\n",
    "- Лучший результат F1:**0.763**\n",
    "- CPU times: user 1min 35s, sys: 1.21 s, total: 1min 37s\n",
    "- Wall time: 1min 37s\n",
    "\n",
    "**Random Forest Classifier**\n",
    "\n",
    "- Лучшие параметры: {'criterion': 'entropy', 'max_depth': 130, 'n_estimators': 110}\n",
    "- Лучший результат:**0.567**\n",
    "- CPU times: user 4h 11min 31s, sys: 18 s, total: 4h 11min 49s\n",
    "- Wall time: 4h 11min 51s\n",
    "\n",
    "*Данную модель мы не будем использовать для проверки на тестовой выборке ,т.к. она не проходит по минимальным требованиям метрики*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.0, class_weight='balanced', intercept_scaling=5,\n",
       "                   random_state=1234)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_lr= LogisticRegression(random_state = 1234, class_weight='balanced',C = 5.0, \n",
    "                                  intercept_scaling = 5, penalty = 'l2', solver = 'lbfgs')\n",
    "model_test_lr.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 LogisticRegression: 0.7674508291554185\n"
     ]
    }
   ],
   "source": [
    "predictions_linear = model_test_lr.predict(features_test)\n",
    "f1 = f1_score(target_test,predictions_linear)\n",
    "print(f'F1 LogisticRegression: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 LogisticRegression: 0.7615959119496856\n"
     ]
    }
   ],
   "source": [
    "svc_test =  LinearSVC(random_state = 1234,class_weight ='balanced',\n",
    "                      C= 1.0, max_iter = 300, penalty ='l2')\n",
    "svc_test.fit(features_train,target_train)\n",
    "predictions_svc = svc_test.predict(features_test)\n",
    "f1 = f1_score(target_test,predictions_svc)\n",
    "print(f'F1 LogisticRegression: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Тестирование было сделано верно!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Для обучения и использования подходят обе линейные модели, LogisticRegressor и LinearSVC. \n",
    "- Последняя обучается значительно быстрее, при этом результат у нее получился практически такой же\n",
    "- Для больших выборок я бы использовал LinearCSV\n",
    "- Сложные ансамблевые модели обучаются долго даже на такой выборке и дают более низкий результат для данного набора данных\n",
    "- Дерево решений так же не показало достаточного значения F1 для дальнейшей реализации\n",
    "\n",
    "**Значения F1**\n",
    "\n",
    " - **Logistic Regression** - 0.767\n",
    " - **Linear SVC**  - 0.761\n",
    " \n",
    " Обе модели удовлетворяют условию задания"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 439,
    "start_time": "2022-06-08T15:31:11.784Z"
   },
   {
    "duration": 2374,
    "start_time": "2022-06-08T15:32:22.391Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-08T15:32:40.465Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-08T15:32:57.389Z"
   },
   {
    "duration": 2,
    "start_time": "2022-06-08T15:33:19.005Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-08T15:33:25.297Z"
   },
   {
    "duration": 13234,
    "start_time": "2022-06-08T15:36:27.138Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-08T15:37:20.297Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T15:37:23.386Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T15:38:28.122Z"
   },
   {
    "duration": 376,
    "start_time": "2022-06-08T15:38:30.484Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T15:39:00.701Z"
   },
   {
    "duration": 24002,
    "start_time": "2022-06-08T15:39:04.178Z"
   },
   {
    "duration": 21,
    "start_time": "2022-06-08T15:40:55.590Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T15:42:43.725Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-08T15:46:12.767Z"
   },
   {
    "duration": 184,
    "start_time": "2022-06-08T15:46:20.413Z"
   },
   {
    "duration": 166,
    "start_time": "2022-06-08T15:46:41.307Z"
   },
   {
    "duration": 2382,
    "start_time": "2022-06-08T15:47:07.063Z"
   },
   {
    "duration": 161,
    "start_time": "2022-06-08T15:47:15.497Z"
   },
   {
    "duration": 197,
    "start_time": "2022-06-08T16:54:35.062Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-08T16:56:01.391Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-08T16:56:08.171Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-08T16:56:19.042Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T16:59:08.882Z"
   },
   {
    "duration": 490,
    "start_time": "2022-06-08T17:00:01.991Z"
   },
   {
    "duration": 144,
    "start_time": "2022-06-08T17:01:13.351Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:04:46.602Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:04:51.602Z"
   },
   {
    "duration": 140,
    "start_time": "2022-06-08T17:04:53.653Z"
   },
   {
    "duration": 188,
    "start_time": "2022-06-08T17:05:05.149Z"
   },
   {
    "duration": 158,
    "start_time": "2022-06-08T17:05:14.412Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-08T17:05:23.258Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:05:27.900Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:05:29.599Z"
   },
   {
    "duration": 4717,
    "start_time": "2022-06-08T17:05:32.499Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-08T17:05:50.839Z"
   },
   {
    "duration": 2234,
    "start_time": "2022-06-08T17:06:18.065Z"
   },
   {
    "duration": 20350,
    "start_time": "2022-06-08T17:06:25.117Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:06:59.817Z"
   },
   {
    "duration": 145,
    "start_time": "2022-06-08T17:07:13.187Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T17:07:16.456Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T17:07:18.279Z"
   },
   {
    "duration": 101577,
    "start_time": "2022-06-08T17:07:20.759Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-08T17:09:02.339Z"
   },
   {
    "duration": 16,
    "start_time": "2022-06-08T17:17:26.127Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-08T17:18:46.468Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-08T17:19:16.207Z"
   },
   {
    "duration": 307,
    "start_time": "2022-06-08T17:25:40.741Z"
   },
   {
    "duration": 41,
    "start_time": "2022-06-08T17:26:00.997Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:26:28.644Z"
   },
   {
    "duration": 56,
    "start_time": "2022-06-08T17:27:55.154Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-08T17:31:22.162Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T17:31:48.509Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-08T17:32:45.910Z"
   },
   {
    "duration": 33,
    "start_time": "2022-06-08T17:33:15.095Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:33:17.705Z"
   },
   {
    "duration": 839,
    "start_time": "2022-06-08T17:34:17.551Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-08T17:35:21.947Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:36:14.182Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-08T17:37:25.076Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-08T17:38:01.073Z"
   },
   {
    "duration": 11906,
    "start_time": "2022-06-08T17:39:11.996Z"
   },
   {
    "duration": 46,
    "start_time": "2022-06-08T17:40:29.970Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-08T17:40:47.660Z"
   },
   {
    "duration": 19,
    "start_time": "2022-06-08T17:41:03.959Z"
   },
   {
    "duration": 18,
    "start_time": "2022-06-08T17:41:16.243Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-08T17:41:26.028Z"
   },
   {
    "duration": 3965,
    "start_time": "2022-06-08T17:41:53.528Z"
   },
   {
    "duration": 2096,
    "start_time": "2022-06-08T17:41:57.496Z"
   },
   {
    "duration": 35,
    "start_time": "2022-06-08T17:41:59.595Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-08T17:41:59.632Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-08T17:41:59.647Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-08T17:41:59.658Z"
   },
   {
    "duration": 93036,
    "start_time": "2022-06-08T17:41:59.673Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-08T17:43:32.711Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-08T17:43:32.728Z"
   },
   {
    "duration": 44,
    "start_time": "2022-06-08T17:43:32.754Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:43:32.800Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-08T17:43:32.806Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-08T17:43:32.820Z"
   },
   {
    "duration": 11963,
    "start_time": "2022-06-08T17:43:32.830Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-08T17:43:44.795Z"
   },
   {
    "duration": 50,
    "start_time": "2022-06-08T17:56:28.836Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-08T18:00:01.218Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-08T18:10:44.460Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-08T18:32:36.891Z"
   },
   {
    "duration": 332,
    "start_time": "2022-06-08T18:38:31.007Z"
   },
   {
    "duration": 1,
    "start_time": "2022-06-08T18:39:10.492Z"
   },
   {
    "duration": 1488,
    "start_time": "2022-06-08T19:52:07.484Z"
   },
   {
    "duration": 1611,
    "start_time": "2022-06-08T19:52:08.975Z"
   },
   {
    "duration": 36,
    "start_time": "2022-06-08T19:52:10.588Z"
   },
   {
    "duration": 17,
    "start_time": "2022-06-08T19:52:10.626Z"
   },
   {
    "duration": 23,
    "start_time": "2022-06-08T19:52:10.645Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-08T19:52:10.670Z"
   },
   {
    "duration": 12,
    "start_time": "2022-06-08T19:52:10.677Z"
   },
   {
    "duration": 111153,
    "start_time": "2022-06-08T19:52:10.690Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-08T19:54:01.845Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-08T19:54:01.856Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-08T19:54:01.895Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-08T19:54:01.928Z"
   },
   {
    "duration": 15,
    "start_time": "2022-06-08T19:54:01.935Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-08T19:54:01.951Z"
   },
   {
    "duration": 13266,
    "start_time": "2022-06-08T19:54:01.966Z"
   },
   {
    "duration": 4258840,
    "start_time": "2022-06-08T19:54:15.234Z"
   },
   {
    "duration": 147,
    "start_time": "2022-06-08T21:05:14.164Z"
   },
   {
    "duration": 97127,
    "start_time": "2022-06-08T21:05:14.313Z"
   },
   {
    "duration": 2096,
    "start_time": "2022-06-09T01:15:57.508Z"
   },
   {
    "duration": 2128,
    "start_time": "2022-06-09T01:16:02.375Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T01:16:08.577Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T01:16:10.709Z"
   },
   {
    "duration": 97872,
    "start_time": "2022-06-09T01:16:14.475Z"
   },
   {
    "duration": 10,
    "start_time": "2022-06-09T01:17:58.708Z"
   },
   {
    "duration": 24,
    "start_time": "2022-06-09T01:18:01.615Z"
   },
   {
    "duration": 3,
    "start_time": "2022-06-09T01:18:04.447Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-09T01:18:08.444Z"
   },
   {
    "duration": 5,
    "start_time": "2022-06-09T01:18:10.685Z"
   },
   {
    "duration": 11756,
    "start_time": "2022-06-09T01:18:13.793Z"
   },
   {
    "duration": 202,
    "start_time": "2022-06-09T01:18:33.093Z"
   },
   {
    "duration": 4121480,
    "start_time": "2022-06-09T01:19:07.234Z"
   },
   {
    "duration": 15111986,
    "start_time": "2022-06-09T02:27:48.715Z"
   },
   {
    "duration": 799,
    "start_time": "2022-06-09T06:39:40.702Z"
   },
   {
    "duration": 77480627,
    "start_time": "2022-06-09T09:28:26.308Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T07:00:31.073Z"
   },
   {
    "duration": 0,
    "start_time": "2022-06-10T07:00:31.074Z"
   },
   {
    "duration": 43125,
    "start_time": "2022-06-10T07:00:37.333Z"
   },
   {
    "duration": 11,
    "start_time": "2022-06-10T07:01:20.460Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T07:01:53.933Z"
   },
   {
    "duration": 44383,
    "start_time": "2022-06-10T07:02:03.770Z"
   },
   {
    "duration": 225,
    "start_time": "2022-06-10T07:02:48.155Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T07:05:02.079Z"
   },
   {
    "duration": 134,
    "start_time": "2022-06-10T07:13:51.840Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T07:18:54.707Z"
   },
   {
    "duration": 8,
    "start_time": "2022-06-10T07:19:00.830Z"
   },
   {
    "duration": 4,
    "start_time": "2022-06-10T07:19:07.728Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T07:19:32.767Z"
   },
   {
    "duration": 42911,
    "start_time": "2022-06-10T07:19:36.153Z"
   },
   {
    "duration": 103,
    "start_time": "2022-06-10T07:20:19.068Z"
   },
   {
    "duration": 2798,
    "start_time": "2022-06-10T07:40:40.265Z"
   },
   {
    "duration": 2724,
    "start_time": "2022-06-10T07:41:02.791Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T07:49:12.914Z"
   },
   {
    "duration": 2873,
    "start_time": "2022-06-10T07:50:18.400Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T07:50:35.068Z"
   },
   {
    "duration": 3301,
    "start_time": "2022-06-10T07:53:55.964Z"
   },
   {
    "duration": 2870,
    "start_time": "2022-06-10T07:54:28.713Z"
   },
   {
    "duration": 20,
    "start_time": "2022-06-10T07:54:46.144Z"
   },
   {
    "duration": 2697,
    "start_time": "2022-06-10T07:54:48.415Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
